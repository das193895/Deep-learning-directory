{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f1a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4fdec03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elastic_Modulus (GPa)</th>\n",
       "      <th>Load (kN)</th>\n",
       "      <th>Length_of_Beam (m)</th>\n",
       "      <th>X-sectional Width b (mm)</th>\n",
       "      <th>X-sectional Height h (mm)</th>\n",
       "      <th>Max Deflection (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>95</td>\n",
       "      <td>88.62827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>88</td>\n",
       "      <td>39.16701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>91</td>\n",
       "      <td>29.16260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>84</td>\n",
       "      <td>325.68300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>106</td>\n",
       "      <td>168.09220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elastic_Modulus (GPa)  Load (kN)  Length_of_Beam (m)  \\\n",
       "0                    151          2                  11   \n",
       "1                    158          3                   7   \n",
       "2                    158          4                   5   \n",
       "3                    141          1                  15   \n",
       "4                    177          4                  13   \n",
       "\n",
       "   X-sectional Width b (mm)  X-sectional Height h (mm)  Max Deflection (mm)  \n",
       "0                        58                         95             88.62827  \n",
       "1                        61                         88             39.16701  \n",
       "2                        36                         91             29.16260  \n",
       "3                        31                         84            325.68300  \n",
       "4                        62                        106            168.09220  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"beam_data_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12da7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elastic_Modulus (GPa)</th>\n",
       "      <th>Load (kN)</th>\n",
       "      <th>Length_of_Beam (m)</th>\n",
       "      <th>X-sectional Width b (mm)</th>\n",
       "      <th>X-sectional Height h (mm)</th>\n",
       "      <th>Max Deflection (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>95</td>\n",
       "      <td>88.62827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elastic_Modulus (GPa)  Load (kN)  Length_of_Beam (m)  \\\n",
       "0                    151          2                  11   \n",
       "\n",
       "   X-sectional Width b (mm)  X-sectional Height h (mm)  Max Deflection (mm)  \n",
       "0                        58                         95             88.62827  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e08e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for loading the data and train test split\n",
    "\n",
    "def data_preprocessing(csv_file,train_size,test_size,The_target_variable):\n",
    "    \n",
    "    # load the data using pandas\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"The shape of your dataset is : {df.shape}\")\n",
    "    \n",
    "    total_no_of_rows = df.shape[0]\n",
    "    total_no_of_columns = df.shape[1]\n",
    "    \n",
    "    # The input features(dependent features) & The target variable(independent feature)\n",
    "    \n",
    "    X = df.drop(The_target_variable,axis = 1)\n",
    "    y = df[[The_target_variable]]\n",
    "    \n",
    "    # Train_test_split\n",
    "    \n",
    "    no_of_rows_for_training = total_no_of_rows*(train_size/100)\n",
    "    no_of_rows_for_testing = total_no_of_rows*(test_size/100)\n",
    "    \n",
    "    train_X = X.iloc[0:int(no_of_rows_for_training),:] \n",
    "    test_X = X.iloc[int(no_of_rows_for_training):total_no_of_rows,:]\n",
    " \n",
    "    train_y = y.iloc[1:int(no_of_rows_for_training),:]\n",
    "    test_y = y.iloc[int(no_of_rows_for_training):total_no_of_rows,:]\n",
    "    \n",
    "    print(f\"The shape of your traing data set is: {train_X.shape}\")\n",
    "    print(f\"The shape of your testing data set is : {test_X.shape}\")\n",
    "    \n",
    "    ## Convert the pandas dataframe to to Numpy array to do model building\n",
    "    \n",
    "    train_X_arr = train_X.to_numpy()\n",
    "    train_y_arr = train_y.to_numpy()\n",
    "    test_X_arr = test_X.to_numpy()\n",
    "    test_y_arr = test_y.to_numpy()\n",
    "    \n",
    "    print(\"your dataframe has been splitted to a traing and testing dataset as well as it has been converted to numpy array for furthe preprocessing\")\n",
    "    \n",
    "    return train_X_arr, train_y_arr, test_X_arr, test_y_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ababef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of your dataset is : (10000, 6)\n",
      "The shape of your traing data set is: (7500, 5)\n",
      "The shape of your testing data set is : (2500, 5)\n",
      "your dataframe has been splitted to a traing and testing dataset as well as it has been converted to numpy array for furthe preprocessing\n"
     ]
    }
   ],
   "source": [
    "train_X_arr, train_y_arr, test_X_arr, test_y_arr = data_preprocessing(\"beam_data_1.csv\",75,25,\"Max Deflection (mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772ddfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cbba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "331a2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_cost_fn_ridge(feature_matrix, target_var, weight_matrix):\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    X = np.hstack((ones_column, feature_matrix))\n",
    "    y = target_var\n",
    "\n",
    "    no_of_samples = X.shape[0]\n",
    "    no_of_columns = X.shape[1]\n",
    "    \n",
    "    summation = 0.0\n",
    "    \n",
    "    weight_sum = 0.0\n",
    "    \n",
    "    \n",
    "    for x,y in zip(X, y):\n",
    "        y_hat = np.dot(x,weight_matrix)\n",
    "        summation += (y_hat - y) ** 2\n",
    "        \n",
    "    for w in weights:\n",
    "        weight_sum += w ** 2\n",
    "        \n",
    "        \n",
    "    final_cost = (summation / (no_of_samples * 2.0)) + (weight_sum / no_of_columns)\n",
    "\n",
    "    return final_cost[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aceafdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6],\n",
       "       [0.6],\n",
       "       [0.6],\n",
       "       [0.6],\n",
       "       [0.6],\n",
       "       [0.6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = np.zeros((train_X_arr.shape[1] + 1,train_y_arr.shape[1]))\n",
    "weights = np.ones(train_X_arr.shape[1] + 1,).reshape(1,-1).T * 0.6\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359eaa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.]\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in weights:\n",
    "    sum = sum + (i/abs(i))\n",
    "    \n",
    "print(sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f51c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing_cost_fn_ridge(train_X_arr, train_y_arr, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d254acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_ridge(feature_matrix, target_var, weight_matrix,learning_rate,max_iter):\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    cost = np.zeros(((max_iter),1))\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    \n",
    "    X = np.hstack((ones_column, feature_matrix))\n",
    "    \n",
    "    no_of_samples = X.shape[0]\n",
    "    \n",
    "    no_of_columns = X.shape[1]\n",
    "    \n",
    "    \n",
    "    while iteration < max_iter:\n",
    "        \n",
    "        gradient = np.zeros((X.shape[1],)).reshape(1,-1).T\n",
    "        \n",
    "        cost[iteration] = computing_cost_fn_ridge(feature_matrix, target_var, weight_matrix)\n",
    "        \n",
    "        for x,y in zip(X, target_var):\n",
    "            \n",
    "            y_hat = np.dot(x,weight_matrix)\n",
    "            \n",
    "            gradient = gradient + ((y_hat[0] - y[0]) * x.reshape(1,-1).T)  # gradient calculation\n",
    "            \n",
    "        \n",
    "            \n",
    "        weight_sum = 0.0\n",
    "        \n",
    "        for w in weights:\n",
    "            \n",
    "            weight_sum += w \n",
    "            \n",
    "               \n",
    "        weight_matrix -= (learning_rate * ((gradient /no_of_samples) + ((weight_sum)/(2.0*no_of_columns)) ))  # updation of weight matrix\n",
    "        \n",
    "#         print(\"Iteration:\", iteration, \"Cost:\", cost[iteration], \"Weights:\", weight_matrix)\n",
    "        \n",
    "        if iteration > 0 and np.abs(cost[iteration - 1] - cost[iteration]) < 1e-5:\n",
    "            \n",
    "            print(\"cost convergence\")\n",
    "            \n",
    "            break\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        \n",
    "    return cost , weight_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16794b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_descent_ridge(train_X_arr,train_y_arr,weights,0.00001,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cb27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing_cost_fn_ridge(train_X_arr, train_y_arr, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdcc6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_cost_fn_lasso(feature_matrix, target_var, weight_matrix):\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    X = np.hstack((ones_column, feature_matrix))\n",
    "    y = target_var\n",
    "\n",
    "    no_of_samples = X.shape[0]\n",
    "    no_of_columns = X.shape[1]\n",
    "    \n",
    "    summation = 0.0\n",
    "    \n",
    "    weight_sum = 0.0\n",
    "    \n",
    "    \n",
    "    for x,y in zip(X, y):\n",
    "        y_hat = np.dot(x,weight_matrix)\n",
    "        summation += (y_hat - y) ** 2\n",
    "        \n",
    "    for w in weights:\n",
    "        weight_sum += abs(w)\n",
    "        \n",
    "        \n",
    "    final_cost = (summation / (no_of_samples * 2.0)) + (weight_sum / no_of_columns)\n",
    "\n",
    "    return final_cost[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd27f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing_cost_fn_lasso(train_X_arr, train_y_arr, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a41dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_lasso(feature_matrix, target_var, weight_matrix,learning_rate,max_iter):\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    cost = np.zeros(((max_iter),1))\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    \n",
    "    X = np.hstack((ones_column, feature_matrix))\n",
    "    \n",
    "    no_of_samples = X.shape[0]\n",
    "    \n",
    "    no_of_columns = X.shape[1]\n",
    "    \n",
    "    \n",
    "    while iteration < max_iter:\n",
    "        \n",
    "        gradient = np.zeros((X.shape[1],)).reshape(1,-1).T\n",
    "        \n",
    "        cost[iteration] = computing_cost_fn_lasso(feature_matrix, target_var, weight_matrix)\n",
    "        \n",
    "        for x,y in zip(X, target_var):\n",
    "            \n",
    "            y_hat = np.dot(x,weight_matrix)\n",
    "            \n",
    "            gradient = gradient + ((y_hat[0] - y[0]) * x.reshape(1,-1).T)  # gradient calculation\n",
    "            \n",
    "        \n",
    "            \n",
    "        weight_sum = 0.0\n",
    "        \n",
    "        for w in weights:\n",
    "            \n",
    "            weight_sum += w/abs(w) \n",
    "            \n",
    "               \n",
    "        weight_matrix -= (learning_rate * ((gradient /no_of_samples) + ((weight_sum[0])/no_of_columns) ))  # updation of weight matrix\n",
    "        \n",
    "#         print(\"Iteration:\", iteration, \"Cost:\", cost[iteration], \"Weights:\", weight_matrix)\n",
    "        \n",
    "        if iteration > 0 and np.abs(cost[iteration - 1] - cost[iteration]) < 1e-5:\n",
    "            \n",
    "            print(\"cost convergence\")\n",
    "            \n",
    "            break\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        \n",
    "    return cost , weight_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "883ba0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_descent_lasso(train_X_arr,train_y_arr,weights,0.00001,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa00944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b035b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71c2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cost_poly_basis(feature_matrix, target_var, weight_matrix, degree):\n",
    "#     \"\"\"\n",
    "#     Compute the cost function for polynomial basis functions.\n",
    "\n",
    "#     Parameters:\n",
    "#     - feature_matrix: Input feature matrix (numpy array)\n",
    "#     - target_var: Target variable (numpy array)\n",
    "#     - weight_matrix: Coefficient matrix (numpy array)\n",
    "#     - degree: Degree of the polynomial basis function\n",
    "\n",
    "#     Returns:\n",
    "#     - final_cost: The computed cost (scalar)\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Add a column of ones to the feature matrix\n",
    "#     ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "#     X = np.hstack((ones_column, feature_matrix))\n",
    "    \n",
    "#     print(X)\n",
    "    \n",
    "#     d = 0\n",
    "    \n",
    "#     for x in X:\n",
    "#         new_arr = np.power(x,d)\n",
    "#         x[d] = new_arr\n",
    "#         x = np.power(x,d)\n",
    "#         d = d+1\n",
    "        \n",
    "#     print(\"change\")\n",
    "#     print(X)\n",
    "\n",
    "#     y = target_var\n",
    "#     no_of_samples = X.shape[0]\n",
    "\n",
    "#     # Calculate the cost\n",
    "#     summation = 0.0\n",
    "#     for x, y in zip(X, y):\n",
    "#         y_hat = np.dot(x, weight_matrix)\n",
    "#         summation += (y_hat - y) ** 2\n",
    "\n",
    "#     final_cost = summation / (no_of_samples * 2.0)\n",
    "\n",
    "#     return final_cost[0]\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming you have feature_matrix, target_var, and weight_matrix defined\n",
    "# degree = 2  # Example degree for the polynomial basis function\n",
    "# cost = compute_cost_poly_basis(train_X_arr,train_y_arr, weights, degree)\n",
    "# print(\"Cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe5cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "459396ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_poly(X):\n",
    "    \n",
    "    no_of_samples = X.shape[0]\n",
    "    \n",
    "    no_of_columns = X.shape[1]\n",
    "    \n",
    "    pre_final_matrix = np.ones((no_of_columns,no_of_samples))\n",
    "    \n",
    "    d = 0\n",
    "    \n",
    "    for x in X.T:\n",
    "        \n",
    "        pre_final_matrix[d,:] =  np.power(x,d).reshape(1,-1)\n",
    "        \n",
    "        d = d + 1\n",
    "        \n",
    "    final_matrix = pre_final_matrix.T\n",
    "    \n",
    "    return final_matrix\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc8c60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1 = np.ones(train_X_arr.shape[1] + 1,).reshape(1,-1).T * 0\n",
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c8c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_cost_fn_poly(feature_matrix, target_var, weight_matrix):\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    X_in = np.hstack((ones_column, feature_matrix))\n",
    "    y = target_var\n",
    "    \n",
    "    X = convert_input_poly(X_in)\n",
    "\n",
    "    no_of_samples = X.shape[0]\n",
    "    \n",
    "    summation = 0.0;\n",
    "    \n",
    "    \n",
    "    for x,y in zip(X, y):\n",
    "        y_hat = np.dot(x,weight_matrix)\n",
    "        summation += (y_hat - y) ** 2\n",
    "        \n",
    "    final_cost = summation / (no_of_samples * 2.0)\n",
    "\n",
    "    return final_cost[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57fc317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_poly(feature_matrix, target_var, weight_matrix,learning_rate,max_iter):\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    cost = np.zeros(((max_iter),1))\n",
    "    \n",
    "    ones_column = np.ones((feature_matrix.shape[0], 1))\n",
    "    \n",
    "    X_in = np.hstack((ones_column, feature_matrix))\n",
    "    \n",
    "    X = convert_input_poly(X_in)\n",
    "    \n",
    "    no_of_samples = X.shape[0]\n",
    "    \n",
    "    \n",
    "    while iteration < max_iter:\n",
    "        \n",
    "        gradient = np.zeros((X.shape[1],)).reshape(1,-1).T\n",
    "        \n",
    "        cost[iteration] = computing_cost_fn_poly(feature_matrix, target_var, weight_matrix)\n",
    "        \n",
    "        for x,y in zip(X, target_var):\n",
    "            \n",
    "            y_hat = np.dot(x,weight_matrix)\n",
    "            \n",
    "            gradient = gradient + ((y_hat[0] - y[0]) * x.reshape(1,-1).T)  # gradient calculation\n",
    "            \n",
    "        \n",
    "               \n",
    "        weight_matrix -= (learning_rate * (gradient)/no_of_samples) # updation of weight matrix\n",
    "        \n",
    "        if iteration > 0 and np.abs(cost[iteration - 1] - cost[iteration]) < 1e-4:\n",
    "            \n",
    "            print(\"cost convergence\")\n",
    "            \n",
    "            break\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        \n",
    "    return cost , weight_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0987463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38285.00043349855"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computing_cost_fn_poly(train_X_arr, train_y_arr, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5832cd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[38285.0004335 ],\n",
       "        [24971.62471908],\n",
       "        [24683.89044309],\n",
       "        ...,\n",
       "        [24676.55051407],\n",
       "        [24676.55002143],\n",
       "        [24676.5495288 ]]),\n",
       " array([[6.02941616e-16],\n",
       "        [8.95210750e-14],\n",
       "        [6.28296020e-15],\n",
       "        [8.79281300e-13],\n",
       "        [4.45634818e-09],\n",
       "        [1.78584190e-08]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_poly(train_X_arr, train_y_arr, weights1,1e-20,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475890a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
