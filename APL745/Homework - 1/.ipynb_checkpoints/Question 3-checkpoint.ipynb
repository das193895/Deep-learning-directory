{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "643e2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "990f7117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e83afb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variety   \n",
       "Setosa        50\n",
       "Versicolor    50\n",
       "Virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"variety\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "261479df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for loading the data and train test split\n",
    "\n",
    "'''\n",
    "--> Enter the name of the file as a string for the variable -- \"csv_file\" \n",
    "--> Enter the name of the \"target variable\" as a string for the variable -- \"target_variable\"\n",
    "--> train_size , test_size -- The ratio you want to split the data (80 ,20)\n",
    "\n",
    "'''\n",
    "\n",
    "def data_preprocessing(csv_file,train_size,test_size,The_target_variable):\n",
    "    \n",
    "    # load the data using pandas\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    df[\"variety\"] = df[\"variety\"].replace({\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2})\n",
    "    \n",
    "    print(f\"The shape of your dataset is : {df.shape}\")\n",
    "    \n",
    "    total_no_of_rows = df.shape[0]\n",
    "    total_no_of_columns = df.shape[1]\n",
    "    \n",
    "    # The input features(dependent features) & The target variable(independent feature)\n",
    "    \n",
    "    X = df.drop(The_target_variable,axis = 1)\n",
    "    y = df[[The_target_variable]]\n",
    "    \n",
    "    # Train_test_split\n",
    "    \n",
    "    X = df.drop(The_target_variable, axis=1)\n",
    "    y = df[The_target_variable]\n",
    "    \n",
    "    # Train-test split\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=train_size/100, test_size=test_size/100, random_state=42)\n",
    "    \n",
    "    print(f\"The shape of your traing data set is: {train_X.shape}\")\n",
    "    print(f\"The shape of your testing data set is : {test_X.shape}\")\n",
    "    \n",
    "    ## Convert the pandas dataframe to to Numpy array to do model building\n",
    "    \n",
    "    train_X_arr = train_X.to_numpy()\n",
    "    train_y_arr = train_y.to_numpy().flatten()\n",
    "    test_X_arr = test_X.to_numpy()\n",
    "    test_y_arr = test_y.to_numpy().flatten()\n",
    "    \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    train_X_tensor = torch.tensor(train_X_arr, dtype=torch.float32)\n",
    "    train_y_tensor = torch.tensor(train_y_arr, dtype=torch.long) \n",
    "    test_X_tensor = torch.tensor(test_X_arr, dtype=torch.float32)\n",
    "    test_y_tensor = torch.tensor(test_y_arr, dtype=torch.long)\n",
    "    \n",
    "    print(\"your dataframe has been splitted to a traing and testing dataset as well as it has been converted to  for furthe preprocessing\")\n",
    "    \n",
    "    return train_X_tensor,train_y_tensor,test_X_tensor,test_y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "333b6cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of your dataset is : (150, 5)\n",
      "The shape of your traing data set is: (120, 4)\n",
      "The shape of your testing data set is : (30, 4)\n",
      "your dataframe has been splitted to a traing and testing dataset as well as it has been converted to  for furthe preprocessing\n"
     ]
    }
   ],
   "source": [
    "## Doing a train test split in 80:20 ratio\n",
    "\n",
    "train_X_tensor,train_y_tensor,test_X_tensor,test_y_tensor = data_preprocessing(\"iris.csv\",80,20,\"variety\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e0b0ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "test_dataset = TensorDataset(test_X_tensor, test_y_tensor)\n",
    "    \n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b10a618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Artificial_NN_A(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Artificial_NN_A, self).__init__()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(4,20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20,3)  \n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input_d):\n",
    "        hidden_outcome = self.hidden_layers(input_d)\n",
    "        final_predictions = self.softmax(hidden_outcome)\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e922f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Network(num_of_epochs, learning_rate, training_set):\n",
    "    \n",
    "    ANN = Artificial_NN_A()  \n",
    "\n",
    "    # choosing the cross entropy loss\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # choose ADAM optimizer and learning rate\n",
    "    optimizer = optim.Adam(ANN.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_of_epochs+1):\n",
    "        \n",
    "        for inputs, labels in training_set:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = ANN(inputs)   # make predictions\n",
    "            \n",
    "            calc_loss = loss_fn(predictions, labels)  # calculate loss\n",
    "            \n",
    "            # Backprop\n",
    "            calc_loss.backward()\n",
    "            \n",
    "            # update all the parameters\n",
    "            optimizer.step()\n",
    "                \n",
    "    return ANN  # return the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "560fd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Train_Network(100, 0.001,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a542d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Network(test_set, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_set:\n",
    "            predictions = model(inputs)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = (correct / total)*100\n",
    "    misclafication_rate = 100 - accuracy\n",
    "    print(f'misclassification rate on the given data set: {misclafication_rate}')\n",
    "    return misclafication_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8e38f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassification rate on the given data set: 3.3333333333333286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3333333333333286"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Network(test_loader,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01aaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
